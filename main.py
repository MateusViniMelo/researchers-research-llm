import os
import time

from deep_translator import GoogleTranslator
from dotenv import load_dotenv
from scholarly import scholarly
from transformers import pipeline

load_dotenv()
# Configurar a API da Hugging Face
HUGGINGFACEHUB_API_TOKEN = os.getenv(
    "HUGGINGFACEHUB_API_TOKEN")

if not HUGGINGFACEHUB_API_TOKEN:
    raise ValueError(
        "‚ùå ERRO: A vari√°vel de ambiente HUGGINGFACEHUB_API_TOKEN n√£o est√° definida ou est√° vazia."
    )


def translate_to_english(text):
    """Traduz um termo do portugu√™s para o ingl√™s automaticamente."""
    return GoogleTranslator(source="auto", target="en").translate(text)


def search_researchers(topic, max_results=10):
    """
    Busca pesquisadores no Google Scholar com base em um tema espec√≠fico.

    :param topic: Tema de interesse
    :param max_results: N√∫mero m√°ximo de pesquisadores a retornar
    :return: Lista de dicion√°rios com nome, afilia√ß√£o e link de cita√ß√µes
    """
    # Traduzir o termo para ingl√™s antes da busca
    translated_topic = translate_to_english(topic)

    search_query = scholarly.search_author(translated_topic)
    researchers = []

    for i, author in enumerate(search_query):
        if i >= max_results:
            break

        try:
            author_info = scholarly.fill(author, sections=["basic"])
            scholar_id = author_info.get("scholar_id", "N/A")
            citations_link = (
                f"https://scholar.google.com/citations?user={scholar_id}"
                if scholar_id != "N/A"
                else "N/A"
            )

            researcher_data = {
                "Nome": author_info.get("name", "N/A"),
                "Afilia√ß√£o": author_info.get("affiliation", "N/A"),
                "Link de Cita√ß√µes": citations_link,
            }
            researchers.append(researcher_data)

            # Delay para evitar bloqueio do Google Scholar
            time.sleep(1)

        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao processar autor: {e}")

    return researchers


def generate_response_with_huggingface(researchers):
    """
    Utiliza a API da Hugging Face para formatar uma resposta com os pesquisadores encontrados.

    :param researchers: Lista de dicion√°rios com informa√ß√µes dos pesquisadores
    :return: Texto gerado pelo modelo
    """
    model = "gpt2-medium"  # Modelo menor e mais leve que o OPT-1.3B
    generator = pipeline("text-generation", model=model)

    context = "\n".join(
        [
            f"- Nome: {r['Nome']}\n  Afilia√ß√£o: {r['Afilia√ß√£o']}\n  Link de Cita√ß√µes: {r['Link de Cita√ß√µes']}\n"
            for r in researchers
        ]
    )

    prompt = f"Forne√ßa as informa√ß√µes dos seguintes pesquisadores de forma organizada:\n{context}"

    response = generator(prompt, max_new_tokens=100,
                         do_sample=True, truncation=True, )

    return response[0]["generated_text"]


if __name__ == "__main__":
    topic = input("üîé Digite o tema da pesquisa: ")
    researchers = search_researchers(topic)

    if researchers:
        print("üìö Pesquisadores encontrados:")
        response = generate_response_with_huggingface(researchers)
        print(response)
    else:
        print("‚ö†Ô∏è Nenhum pesquisador encontrado.")
